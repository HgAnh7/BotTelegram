import requests
import json
import os
import time
from datetime import datetime
from telegram import Update
from telegram.ext import Application, CommandHandler, ContextTypes
import logging
import threading

# C·∫•u h√¨nh logging
logging.basicConfig(
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s',
    level=logging.INFO
)
logger = logging.getLogger(__name__)

# Thay th·∫ø b·∫±ng token bot c·ªßa b·∫°n
BOT_TOKEN = os.getenv("TELEGRAM_TOKEN")

class URLCollector:
    def __init__(self):
        self.collected_urls = set()  # S·ª≠ d·ª•ng set ƒë·ªÉ tr√°nh tr√πng l·∫∑p
        self.is_collecting = False
    
    def fetch_url_from_api(self, api_url, url_key="url", timeout=10):
        """
        G·ªçi API v√† l·∫•y URL t·ª´ JSON response
        
        Args:
            api_url: URL c·ªßa API c·∫ßn g·ªçi
            url_key: Key ch·ª©a URL trong JSON response (m·∫∑c ƒë·ªãnh l√† "url")
            timeout: Timeout cho request (gi√¢y)
        
        Returns:
            URL n·∫øu t√¨m th·∫•y, None n·∫øu kh√¥ng
        """
        try:
            headers = {
                'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36'
            }
            
            response = requests.get(api_url, headers=headers, timeout=timeout)
            
            if response.status_code == 200:
                try:
                    data = response.json()
                    url = self.extract_url_from_json(data, url_key)
                    return url
                except json.JSONDecodeError:
                    logger.error("Response kh√¥ng ph·∫£i JSON h·ª£p l·ªá")
                    return None
            else:
                logger.warning(f"API tr·∫£ v·ªÅ status code: {response.status_code}")
                return None
                
        except requests.exceptions.Timeout:
            logger.error("Request timeout")
            return None
        except requests.exceptions.RequestException as e:
            logger.error(f"L·ªói khi g·ªçi API: {e}")
            return None
    
    def extract_url_from_json(self, data, url_key):
        """
        Tr√≠ch xu·∫•t URL t·ª´ JSON data (h·ªó tr·ª£ nested)
        
        Args:
            data: JSON data
            url_key: Key c·∫ßn t√¨m
            
        Returns:
            URL n·∫øu t√¨m th·∫•y, None n·∫øu kh√¥ng
        """
        if isinstance(data, dict):
            if url_key in data:
                return data[url_key]
            
            # T√¨m trong nested objects
            for value in data.values():
                if isinstance(value, (dict, list)):
                    result = self.extract_url_from_json(value, url_key)
                    if result:
                        return result
                        
        elif isinstance(data, list):
            for item in data:
                result = self.extract_url_from_json(item, url_key)
                if result:
                    return result
        
        return None
    
    def collect_urls(self, api_url, num_requests, url_key="url", progress_callback=None):
        """
        Thu th·∫≠p URLs t·ª´ API
        
        Args:
            api_url: URL c·ªßa API
            num_requests: S·ªë l·∫ßn request
            url_key: Key ch·ª©a URL trong JSON
            progress_callback: Callback ƒë·ªÉ c·∫≠p nh·∫≠t ti·∫øn tr√¨nh
        """
        self.is_collecting = True
        new_urls_count = 0
        duplicate_count = 0
        error_count = 0
        
        for i in range(num_requests):
            if not self.is_collecting:  # Cho ph√©p d·ª´ng gi·ªØa ch·ª´ng
                break
                
            url = self.fetch_url_from_api(api_url, url_key)
            
            if url:
                if url not in self.collected_urls:
                    self.collected_urls.add(url)
                    new_urls_count += 1
                    logger.info(f"Th√™m URL m·ªõi: {url}")
                else:
                    duplicate_count += 1
                    logger.info(f"URL tr√πng l·∫∑p b·ªè qua: {url}")
            else:
                error_count += 1
            
            # Callback ƒë·ªÉ c·∫≠p nh·∫≠t ti·∫øn tr√¨nh
            if progress_callback:
                progress_callback(i + 1, num_requests, new_urls_count, duplicate_count, error_count)
            
            # Delay nh·ªè ƒë·ªÉ tr√°nh spam API
            time.sleep(0.5)
        
        self.is_collecting = False
        return new_urls_count, duplicate_count, error_count
    
    def save_urls_to_file(self, filename="urls.txt"):
        """L∆∞u URLs v√†o file"""
        try:
            with open(filename, 'w', encoding='utf-8') as f:
                f.write(f"# URLs ƒë∆∞·ª£c thu th·∫≠p v√†o {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\n")
                f.write(f"# T·ªïng c·ªông: {len(self.collected_urls)} URLs\n\n")
                
                for url in sorted(self.collected_urls):
                    f.write(f"{url}\n")
            
            return filename
        except Exception as e:
            logger.error(f"L·ªói khi l∆∞u file: {e}")
            return None
    
    def clear_urls(self):
        """X√≥a t·∫•t c·∫£ URLs ƒë√£ thu th·∫≠p"""
        self.collected_urls.clear()
    
    def stop_collecting(self):
        """D·ª´ng qu√° tr√¨nh thu th·∫≠p"""
        self.is_collecting = False

# Kh·ªüi t·∫°o collector
collector = URLCollector()

async def start(update: Update, context: ContextTypes.DEFAULT_TYPE):
    """L·ªánh /start"""
    welcome_message = """
ü§ñ *Bot Thu Th·∫≠p URLs*

C√°c l·ªánh c√≥ s·∫µn:
‚Ä¢ `/collect <api_url> <s·ªë_l·∫ßn> [url_key]` - Thu th·∫≠p URLs t·ª´ API
‚Ä¢ `/status` - Xem tr·∫°ng th√°i hi·ªán t·∫°i
‚Ä¢ `/download` - T·∫£i file urls.txt
‚Ä¢ `/clear` - X√≥a t·∫•t c·∫£ URLs ƒë√£ thu th·∫≠p
‚Ä¢ `/stop` - D·ª´ng qu√° tr√¨nh thu th·∫≠p
‚Ä¢ `/help` - Xem h∆∞·ªõng d·∫´n chi ti·∫øt

*V√≠ d·ª•:*
`/collect https://api.example.com/data 10 url`
    """
    await update.message.reply_text(welcome_message, parse_mode='Markdown')

async def help_command(update: Update, context: ContextTypes.DEFAULT_TYPE):
    """L·ªánh /help"""
    help_text = """
üìñ *H∆∞·ªõng D·∫´n S·ª≠ D·ª•ng*

*L·ªánh collect:*
`/collect <api_url> <s·ªë_l·∫ßn> [url_key]`

‚Ä¢ `api_url`: URL c·ªßa API c·∫ßn g·ªçi
‚Ä¢ `s·ªë_l·∫ßn`: S·ªë l·∫ßn request API (1-1000)
‚Ä¢ `url_key`: Key ch·ª©a URL trong JSON (m·∫∑c ƒë·ªãnh: "url")

*V√≠ d·ª•:*
‚Ä¢ `/collect https://picsum.photos/200/300 20`
‚Ä¢ `/collect https://api.example.com/data 50 download_url`
‚Ä¢ `/collect https://randomuser.me/api 10 picture`

*C√°c API test c√≥ th·ªÉ d√πng:*
‚Ä¢ `https://jsonplaceholder.typicode.com/posts/1` - key: url
‚Ä¢ `https://httpbin.org/json` - key: url
‚Ä¢ `https://api.github.com/repos/microsoft/vscode` - key: clone_url

*L∆∞u √Ω:*
‚Ä¢ Bot s·∫Ω t·ª± ƒë·ªông lo·∫°i b·ªè URLs tr√πng l·∫∑p
‚Ä¢ File s·∫Ω ƒë∆∞·ª£c l∆∞u v·ªõi t√™n `urls.txt`
‚Ä¢ T·ªëi ƒëa 1000 requests m·ªói l·∫ßn
‚Ä¢ S·ª≠ d·ª•ng `/stop` ƒë·ªÉ d·ª´ng gi·ªØa ch·ª´ng
    """
    await update.message.reply_text(help_text, parse_mode='Markdown')

async def collect_urls_command(update: Update, context: ContextTypes.DEFAULT_TYPE):
    """L·ªánh /collect"""
    if len(context.args) < 2:
        await update.message.reply_text(
            "‚ùå S·ª≠ d·ª•ng: `/collect <api_url> <s·ªë_l·∫ßn> [url_key]`",
            parse_mode='Markdown'
        )
        return
    
    if collector.is_collecting:
        await update.message.reply_text("‚ö†Ô∏è Bot ƒëang thu th·∫≠p URLs. D√πng `/stop` ƒë·ªÉ d·ª´ng tr∆∞·ªõc.")
        return
    
    try:
        api_url = context.args[0]
        num_requests = int(context.args[1])
        url_key = context.args[2] if len(context.args) > 2 else "url"
        
        if num_requests < 1 or num_requests > 1000:
            await update.message.reply_text("‚ùå S·ªë l·∫ßn request ph·∫£i t·ª´ 1-1000")
            return
        
        # G·ª≠i th√¥ng b√°o b·∫Øt ƒë·∫ßu
        progress_msg = await update.message.reply_text("üöÄ B·∫Øt ƒë·∫ßu thu th·∫≠p URLs...")
        
        # H√†m c·∫≠p nh·∫≠t ti·∫øn tr√¨nh ƒë∆°n gi·∫£n h∆°n
        def update_progress(current, total, new_count, duplicate_count, error_count):
            if current % 5 == 0 or current == total:  # C·∫≠p nh·∫≠t m·ªói 5 l·∫ßn
                progress_text = f"üìä Ti·∫øn tr√¨nh: {current}/{total}\n"
                progress_text += f"‚úÖ URLs m·ªõi: {new_count}\n"
                progress_text += f"üîÑ Tr√πng l·∫∑p: {duplicate_count}\n"
                progress_text += f"‚ùå L·ªói: {error_count}"
                
                # L∆∞u ƒë·ªÉ c·∫≠p nh·∫≠t sau (tr√°nh async trong sync function)
                update_progress.last_text = progress_text
        
        update_progress.last_text = "üöÄ B·∫Øt ƒë·∫ßu thu th·∫≠p URLs..."
        
        # Thu th·∫≠p URLs tr·ª±c ti·∫øp (kh√¥ng d√πng thread ƒë·ªÉ tr√°nh l·ªói event loop)
        new_count, duplicate_count, error_count = collector.collect_urls(api_url, num_requests, url_key, update_progress)
        
        # T·∫°o v√† g·ª≠i file ngay l·∫≠p t·ª©c
        if collector.collected_urls:
            try:
                filename = collector.save_urls_to_file()
                if filename and os.path.exists(filename):
                    # T·∫°o caption v·ªõi th·ªëng k√™
                    caption = f"‚úÖ *Thu th·∫≠p ho√†n th√†nh!*\n\n"
                    caption += f"üìä K·∫øt qu·∫£:\n"
                    caption += f"‚Ä¢ URLs m·ªõi: {new_count}\n"
                    caption += f"‚Ä¢ Tr√πng l·∫∑p: {duplicate_count}\n"
                    caption += f"‚Ä¢ L·ªói: {error_count}\n"
                    caption += f"‚Ä¢ T·ªïng URLs: {len(collector.collected_urls)}"
                    
                    # G·ª≠i file v·ªõi caption
                    with open(filename, 'rb') as f:
                        await update.message.reply_document(
                            document=f,
                            filename="urls.txt",
                            caption=caption,
                            parse_mode='Markdown'
                        )
                    
                    # X√≥a file t·∫°m
                    os.remove(filename)
                    
                    # X√≥a message ti·∫øn tr√¨nh
                    await progress_msg.delete()
                    
                else:
                    # N·∫øu kh√¥ng t·∫°o ƒë∆∞·ª£c file, hi·ªÉn th·ªã k·∫øt qu·∫£ text
                    result_text = f"‚úÖ *Ho√†n th√†nh!*\n\n"
                    result_text += f"üìä K·∫øt qu·∫£:\n"
                    result_text += f"‚Ä¢ URLs m·ªõi: {new_count}\n"
                    result_text += f"‚Ä¢ Tr√πng l·∫∑p: {duplicate_count}\n"
                    result_text += f"‚Ä¢ L·ªói: {error_count}\n"
                    result_text += f"‚Ä¢ T·ªïng URLs: {len(collector.collected_urls)}\n\n"
                    result_text += f"‚ùå L·ªói t·∫°o file, d√πng `/download` ƒë·ªÉ th·ª≠ l·∫°i"
                    
                    await progress_msg.edit_text(result_text, parse_mode='Markdown')
                    
            except Exception as file_error:
                # N·∫øu c√≥ l·ªói khi g·ª≠i file
                result_text = f"‚úÖ *Thu th·∫≠p ho√†n th√†nh!*\n\n"
                result_text += f"üìä K·∫øt qu·∫£:\n"
                result_text += f"‚Ä¢ URLs m·ªõi: {new_count}\n"
                result_text += f"‚Ä¢ Tr√πng l·∫∑p: {duplicate_count}\n"
                result_text += f"‚Ä¢ L·ªói: {error_count}\n"
                result_text += f"‚Ä¢ T·ªïng URLs: {len(collector.collected_urls)}\n\n"
                result_text += f"‚ùå L·ªói g·ª≠i file: {str(file_error)}\n"
                result_text += f"D√πng `/download` ƒë·ªÉ t·∫£i file"
                
                await progress_msg.edit_text(result_text, parse_mode='Markdown')
        else:
            # N·∫øu kh√¥ng c√≥ URLs n√†o
            result_text = f"‚ö†Ô∏è *Ho√†n th√†nh nh∆∞ng kh√¥ng c√≥ URLs!*\n\n"
            result_text += f"üìä K·∫øt qu·∫£:\n"
            result_text += f"‚Ä¢ URLs m·ªõi: {new_count}\n"
            result_text += f"‚Ä¢ Tr√πng l·∫∑p: {duplicate_count}\n"
            result_text += f"‚Ä¢ L·ªói: {error_count}\n\n"
            result_text += f"Ki·ªÉm tra l·∫°i API URL v√† key name"
            
            await progress_msg.edit_text(result_text, parse_mode='Markdown')
        
    except ValueError:
        await update.message.reply_text("‚ùå S·ªë l·∫ßn request ph·∫£i l√† s·ªë nguy√™n")
    except Exception as e:
        await update.message.reply_text(f"‚ùå L·ªói: {str(e)}")

async def status_command(update: Update, context: ContextTypes.DEFAULT_TYPE):
    """L·ªánh /status"""
    status_text = f"üìä *Tr·∫°ng Th√°i*\n\n"
    status_text += f"‚Ä¢ T·ªïng URLs: {len(collector.collected_urls)}\n"
    status_text += f"‚Ä¢ ƒêang thu th·∫≠p: {'‚úÖ' if collector.is_collecting else '‚ùå'}\n"
    
    if collector.collected_urls:
        recent_urls = list(collector.collected_urls)[-3:]  # 3 URLs g·∫ßn nh·∫•t
        status_text += f"\n*URLs g·∫ßn nh·∫•t:*\n"
        for i, url in enumerate(recent_urls, 1):
            status_text += f"{i}. `{url[:50]}...`\n"
    
    await update.message.reply_text(status_text, parse_mode='Markdown')

async def download_command(update: Update, context: ContextTypes.DEFAULT_TYPE):
    """L·ªánh /download"""
    if not collector.collected_urls:
        await update.message.reply_text("‚ùå Ch∆∞a c√≥ URLs n√†o ƒë∆∞·ª£c thu th·∫≠p")
        return
    
    try:
        filename = collector.save_urls_to_file()
        if filename and os.path.exists(filename):
            with open(filename, 'rb') as f:
                await update.message.reply_document(
                    document=f,
                    filename=filename,
                    caption=f"üìÅ File ch·ª©a {len(collector.collected_urls)} URLs"
                )
            
            # X√≥a file t·∫°m sau khi g·ª≠i
            os.remove(filename)
        else:
            await update.message.reply_text("‚ùå L·ªói khi t·∫°o file")
    except Exception as e:
        await update.message.reply_text(f"‚ùå L·ªói: {str(e)}")

async def clear_command(update: Update, context: ContextTypes.DEFAULT_TYPE):
    """L·ªánh /clear"""
    count = len(collector.collected_urls)
    collector.clear_urls()
    await update.message.reply_text(f"üóëÔ∏è ƒê√£ x√≥a {count} URLs")

async def stop_command(update: Update, context: ContextTypes.DEFAULT_TYPE):
    """L·ªánh /stop"""
    if collector.is_collecting:
        collector.stop_collecting()
        await update.message.reply_text("‚èπÔ∏è ƒê√£ d·ª´ng qu√° tr√¨nh thu th·∫≠p URLs")
    else:
        await update.message.reply_text("‚ùå Kh√¥ng c√≥ qu√° tr√¨nh thu th·∫≠p n√†o ƒëang ch·∫°y")

def main():
    """H√†m main"""
    if BOT_TOKEN == "YOUR_BOT_TOKEN_HERE":
        print("‚ùå Vui l√≤ng thay th·∫ø BOT_TOKEN b·∫±ng token th·ª±c t·ª´ @BotFather")
        return
    
    # T·∫°o application
    application = Application.builder().token(BOT_TOKEN).build()
    
    # Th√™m handlers
    application.add_handler(CommandHandler("start", start))
    application.add_handler(CommandHandler("help", help_command))
    application.add_handler(CommandHandler("collect", collect_urls_command))
    application.add_handler(CommandHandler("status", status_command))
    application.add_handler(CommandHandler("download", download_command))
    application.add_handler(CommandHandler("clear", clear_command))
    application.add_handler(CommandHandler("stop", stop_command))
    
    # Ch·∫°y bot
    print("ü§ñ Bot ƒëang ch·∫°y...")
    application.run_polling()

if __name__ == '__main__':
    try:
        main()
    except KeyboardInterrupt:
        print("\nüëã Bot ƒë√£ d·ª´ng")
