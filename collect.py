import asyncio
import aiohttp
import os
import time
from datetime import datetime
from telegram import Update
from telegram.ext import Application, CommandHandler, ContextTypes
import logging
from typing import Set, Optional, Tuple

logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

BOT_TOKEN = os.getenv("TELEGRAM_TOKEN")
MAX_URLS = 10_000  # Gi·ªõi h·∫°n n·ªôi b·ªô, kh√¥ng hi·ªÉn th·ªã cho ng∆∞·ªùi d√πng

class URLCollector:
    def __init__(self):
        self.collected_urls: Set[str] = set()
        self.collection_tasks = {}
        self.session = None

    async def get_session(self):
        if self.session is None or self.session.closed:
            timeout = aiohttp.ClientTimeout(total=10, connect=5)
            connector = aiohttp.TCPConnector(limit=100, limit_per_host=20)
            self.session = aiohttp.ClientSession(
                timeout=timeout,
                connector=connector,
                headers={'User-Agent': 'Mozilla/5.0 (compatible; URLBot/1.0)'}
            )
        return self.session

    async def close_session(self):
        if self.session and not self.session.closed:
            await self.session.close()

    def extract_url_from_json(self, data, url_key: str) -> Optional[str]:
        if isinstance(data, dict):
            if url_key in data:
                return data[url_key]
            for value in data.values():
                if isinstance(value, (dict, list)):
                    result = self.extract_url_from_json(value, url_key)
                    if result:
                        return result
        elif isinstance(data, list):
            for item in data:
                result = self.extract_url_from_json(item, url_key)
                if result:
                    return result
        return None

    async def fetch_single_url(self, api_url: str, url_key: str) -> Optional[str]:
        try:
            session = await self.get_session()
            async with session.get(api_url) as response:
                if response.status == 200:
                    data = await response.json()
                    return self.extract_url_from_json(data, url_key)
        except Exception as e:
            logger.debug(f"L·ªói khi l·∫•y URL: {e}")
        return None

    async def collect_urls(self, chat_id: int, api_url: str, request_count: int,
                           url_key: str, progress_callback) -> Tuple[int, int, int]:
        new_count = dup_count = err_count = 0
        batch_size = min(100, max(10, request_count // 10))

        for start in range(0, request_count, batch_size):
            if chat_id not in self.collection_tasks:
                break

            if len(self.collected_urls) >= MAX_URLS:
                break

            end = min(start + batch_size, request_count)
            tasks = [self.fetch_single_url(api_url, url_key) for _ in range(end - start)]

            try:
                results = await asyncio.wait_for(asyncio.gather(*tasks, return_exceptions=True), timeout=30.0)
                for result in results:
                    if isinstance(result, Exception):
                        err_count += 1
                    elif result:
                        if result not in self.collected_urls:
                            if len(self.collected_urls) < MAX_URLS:
                                self.collected_urls.add(result)
                                new_count += 1
                            else:
                                break
                        else:
                            dup_count += 1
                    else:
                        err_count += 1

                if progress_callback:
                    await progress_callback(end, request_count, new_count, dup_count, err_count)

                await asyncio.sleep(0.05)

            except asyncio.TimeoutError:
                err_count += end - start

        return new_count, dup_count, err_count

    def generate_filename(self, chat_id: int = None, prefix: str = "urls", ext: str = "txt") -> str:
        timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')
        return f"{prefix}_{chat_id}_{timestamp}.{ext}" if chat_id else f"{prefix}_{timestamp}.{ext}"

    def save_urls_to_file(self, filename: str = None, chat_id: int = None) -> Optional[str]:
        if not filename:
            filename = self.generate_filename(chat_id)
        try:
            with open(filename, 'w', encoding='utf-8') as f:
                f.write(f"# Danh s√°ch URL thu th·∫≠p ƒë∆∞·ª£c t·∫°i {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\n")
                f.write(f"# T·ªïng c·ªông: {len(self.collected_urls)} URL\n\n")
                for url in sorted(self.collected_urls):
                    f.write(f"{url}\n")
            return filename
        except Exception as e:
            logger.error(f"L·ªói l∆∞u t·ªáp: {e}")
            return None

collector = URLCollector()

async def start(update: Update, context: ContextTypes.DEFAULT_TYPE):
    await update.message.reply_text(
        "ü§ñ *Bot Thu Th·∫≠p URL*\n\n"
        "L·ªánh c√≥ th·ªÉ s·ª≠ d·ª•ng:\n"
        "‚Ä¢ /collect <api_url> <s·ªë_l∆∞·ª£ng> [t√™n_tr∆∞·ªùng_url] - B·∫Øt ƒë·∫ßu thu th·∫≠p URL\n"
        "‚Ä¢ /status - Xem tr·∫°ng th√°i bot\n"
        "‚Ä¢ /download - T·∫£i danh s√°ch URL ƒë√£ thu th·∫≠p\n"
        "‚Ä¢ /stop - D·ª´ng qu√° tr√¨nh thu th·∫≠p\n"
        "‚Ä¢ /clear - Xo√° to√†n b·ªô URL ƒë√£ l∆∞u\n\n"
        "*V√≠ d·ª•:* `/collect https://picsum.photos/200/300 100`",
        parse_mode='Markdown'
    )

async def collect(update: Update, context: ContextTypes.DEFAULT_TYPE):
    if len(context.args) < 2:
        await update.message.reply_text("‚ùå C√∫ ph√°p: `/collect <api_url> <s·ªë_l∆∞·ª£ng> [t√™n_tr∆∞·ªùng_url]`", parse_mode='Markdown')
        return

    chat_id = update.effective_chat.id
    if chat_id in collector.collection_tasks:
        await update.message.reply_text("‚ö†Ô∏è ƒêang thu th·∫≠p. D√πng l·ªánh `/stop` ƒë·ªÉ d·ª´ng.")
        return

    try:
        api_url = context.args[0]
        request_count = int(context.args[1])
        url_key = context.args[2] if len(context.args) > 2 else "url"

        if not (1 <= request_count <= 10_000):
            await update.message.reply_text("‚ùå S·ªë l∆∞·ª£ng URL ph·∫£i n·∫±m trong kho·∫£ng 1‚Äì10.000")
            return

        start_time = time.time()
        status_msg = await update.message.reply_text("üöÄ B·∫Øt ƒë·∫ßu thu th·∫≠p...")

        async def update_progress(current, total, new, dup, err):
            elapsed = time.time() - start_time
            speed = current / elapsed if elapsed else 0
            text = (
                f"‚è≥ ƒê√£ x·ª≠ l√Ω: {current}/{total} ({current / total * 100:.1f}%)\n"
                f"‚ö° T·ªëc ƒë·ªô: {speed:.1f} y√™u c·∫ßu/gi√¢y\n"
                f"‚úÖ M·ªõi: {new} | üîÅ Tr√πng: {dup} | ‚ùå L·ªói: {err}\n"
                f"üì¶ T·ªïng URL ƒë√£ l∆∞u: {len(collector.collected_urls)}"
            )
            try:
                await status_msg.edit_text(text)
            except:
                pass

        task = asyncio.create_task(
            collector.collect_urls(chat_id, api_url, request_count, url_key, update_progress)
        )
        collector.collection_tasks[chat_id] = task

        new, dup, err = await task

        if collector.collected_urls:
            filename = collector.save_urls_to_file(chat_id=chat_id)
            if filename:
                total_time = time.time() - start_time
                caption = (
                    f"‚úÖ *Thu th·∫≠p ho√†n t·∫•t!*\n\n"
                    f"‚Ä¢ M·ªõi: {new}\n"
                    f"‚Ä¢ Tr√πng: {dup}\n"
                    f"‚Ä¢ L·ªói: {err}\n"
                    f"‚Ä¢ T·ªïng: {len(collector.collected_urls)} URL\n"
                    f"‚Ä¢ Th·ªùi gian: {total_time:.1f} gi√¢y"
                )
                with open(filename, 'rb') as f:
                    await update.message.reply_document(
                        document=f,
                        filename=os.path.basename(filename),
                        caption=caption,
                        parse_mode='Markdown'
                    )
                os.remove(filename)
                await status_msg.delete()
            else:
                await status_msg.edit_text("‚úÖ Ho√†n t·∫•t! (L·ªói khi l∆∞u t·ªáp)")
        else:
            await status_msg.edit_text("‚ö†Ô∏è Kh√¥ng thu th·∫≠p ƒë∆∞·ª£c URL n√†o. H√£y ki·ªÉm tra API ho·∫∑c t√™n tr∆∞·ªùng URL.")

    except asyncio.CancelledError:
        await update.message.reply_text("‚èπÔ∏è ƒê√£ d·ª´ng thu th·∫≠p")
    except Exception as e:
        await update.message.reply_text(f"‚ùå L·ªói: {str(e)}")
    finally:
        collector.collection_tasks.pop(chat_id, None)

async def status(update: Update, context: ContextTypes.DEFAULT_TYPE):
    chat_id = update.effective_chat.id
    is_collecting = chat_id in collector.collection_tasks

    text = (
        f"üìä *Tr·∫°ng th√°i bot*\n\n"
        f"‚Ä¢ URL ƒë√£ l∆∞u: {len(collector.collected_urls)}\n"
        f"‚Ä¢ ƒêang thu th·∫≠p: {'üü¢ C√≥' if is_collecting else 'üî¥ Kh√¥ng'}\n"
        f"‚Ä¢ S·ªë ti·∫øn tr√¨nh ƒëang ch·∫°y: {len(collector.collection_tasks)}"
    )

    if collector.collected_urls:
        recent = list(collector.collected_urls)[-3:]
        text += "\n\n*URL g·∫ßn nh·∫•t:*\n"
        for i, url in enumerate(recent, 1):
            display = url[:40] + "..." if len(url) > 40 else url
            text += f"{i}. `{display}`\n"

    await update.message.reply_text(text, parse_mode='Markdown')

async def download(update: Update, context: ContextTypes.DEFAULT_TYPE):
    if not collector.collected_urls:
        await update.message.reply_text("‚ùå Ch∆∞a c√≥ URL n√†o ƒë∆∞·ª£c thu th·∫≠p")
        return

    chat_id = update.effective_chat.id
    filename = collector.save_urls_to_file(chat_id=chat_id)

    if filename:
        try:
            with open(filename, 'rb') as f:
                await update.message.reply_document(
                    document=f,
                    filename=os.path.basename(filename),
                    caption=f"üìÅ T·ªïng c·ªông: {len(collector.collected_urls)} URL"
                )
            os.remove(filename)
        except Exception as e:
            await update.message.reply_text(f"‚ùå G·ª≠i t·ªáp l·ªói: {str(e)}")
    else:
        await update.message.reply_text("‚ùå Kh√¥ng th·ªÉ t·∫°o t·ªáp")

async def stop(update: Update, context: ContextTypes.DEFAULT_TYPE):
    chat_id = update.effective_chat.id
    if chat_id in collector.collection_tasks:
        collector.collection_tasks[chat_id].cancel()
        await update.message.reply_text("‚èπÔ∏è ƒê√£ d·ª´ng thu th·∫≠p")
        collector.collection_tasks.pop(chat_id, None)
    else:
        await update.message.reply_text("‚ùå Kh√¥ng c√≥ ti·∫øn tr√¨nh n√†o ƒëang ch·∫°y")

async def clear(update: Update, context: ContextTypes.DEFAULT_TYPE):
    count = len(collector.collected_urls)
    collector.collected_urls.clear()
    await collector.close_session()
    await update.message.reply_text(f"üóëÔ∏è ƒê√£ xo√° {count} URL")

def main():
    if not BOT_TOKEN:
        print("‚ùå TELEGRAM_TOKEN ch∆∞a ƒë∆∞·ª£c thi·∫øt l·∫≠p")
        return

    app = Application.builder().token(BOT_TOKEN).build()

    app.add_handler(CommandHandler("start", start))
    app.add_handler(CommandHandler("collect", collect))
    app.add_handler(CommandHandler("status", status))
    app.add_handler(CommandHandler("download", download))
    app.add_handler(CommandHandler("stop", stop))
    app.add_handler(CommandHandler("clear", clear))

    print("ü§ñ Bot Thu Th·∫≠p URL ƒëang ch·∫°y...")
    app.run_polling()

if __name__ == '__main__':
    try:
        main()
    except KeyboardInterrupt:
        print("\nüëã Bot ƒë√£ d·ª´ng")
    finally:
        asyncio.run(collector.close_session())
